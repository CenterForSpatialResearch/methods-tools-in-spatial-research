<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image-matching: Locating Imagery in 3D Space</title>
    <link rel="stylesheet" href="../main.css">
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@300&display=swap" rel="stylesheet">
    <script src="https://www.gstatic.com/charts/loader.js"></script>
    <script src="https://code.jquery.com/jquery-1.12.4.js"></script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-J2SEN9LXNV"></script>
    <script src="https://d3js.org/d3.v6.min.js"></script>
</head>

<body data-project-name="Image-matching: Locating Imagery in 3D Space"> <!-- The name here is to link Tags from json file (project name)-->
    <div class="top-bar">
   
        <div class="title">
            <a href="../index.html" id="sidePanel">
                Methods and Tutorials in Spatial Research 
            </a>
        </div>

        <div class="button-container" id="about">
            <a href="../about.html">About</a>
        </div>
     </div>
     
<div class="column">
    <div class="column-left">
        <div id="tutorials-side-panel">
            <h3>Workshop Panel: </h3>
            <div class="visual-code-container">
                <div class="tutorials-circle"></div>
                <p id="panel-text"></p>
            </div>
            <h3>Project Tags: </h3>
            <div class="tutorials-ProjectTagsContainer" id="project_tags">
                <!-- Tags will be dynamically inserted here -->
            </div>
        </div>

    </div>
    <div class="column-main">
        <div class="tutorials-section">
        
            <h1>Image-matching: Locating Imagery in 3D Space</h1>
            <h2>Maksym Rokmaniko, The Center for Spatial Technologies</h2>
            <p>Jump to:</p>

            <a href="#image-match-guide">Setup</a><br>
                <a class="indent"href="#setup">Setup</a><br>
                <a class="indent" href="#image-match-source">Processing of Source Materials</a><br>
            <a href="#image-match-georef-aerial">Georeferencing Aerial Photographs</a><br>
                <a class="indent" href="#image-match-contour">Vectorization of Contour Lines</a><br>
                <a class="indent" href="#image-match-contour">Vectorization of Contour Lines</a><br>
                <a class="indent" href="#image-match-contour">Vectorization of Contour Lines</a><br>
                <a class="indent" href="#image-match-contour">Vectorization of Contour Lines</a><br>
                <a class="indent" href="#image-match-contour">Vectorization of Contour Lines</a><br>
            <a href="#image-match-georef-histo">Georeferencing Historical Photographs</a>
                <a class="indent" href="#image-match-contour">Vectorization of Contour Lines</a><br>
                <a class="indent" href="#image-match-contour">Vectorization of Contour Lines</a><br>
    
            <p>In this tutorial, we'll explore how to use the <a href="https://github.com/sptch/image-matcher/tree/main">image-matcher Blender add-on</a> to locate 2D images within a 3D model. This technique is crucial for our ongoing work at the <a href="https://www.spatialtech.info/en">Center for Spatial Technologies</a>, where we've applied it to various projects.</p>
    
            <p>On September 29-30, 1941, more than 33,000 Jews were massacred in Babyn Yar. During the German occupation of Kyiv, between 100,000 and 150,000 people were killed there, including patients of the Kyiv City Psychiatric Hospital, Roma, Ukrainian nationalists, prisoners of war, and local authorities. Before retreating from Kyiv, the Nazis attempted to hide the traces of the massacres. Several hundred prisoners of war from the Syrets internment camp were forced to exhume and burn the remains of the dead.</p>
    
            <p>In the late 50s and early 60s, the landscape of Babyn Yar was fundamentally changed. The spurs were filled with liquid soil and covered over, resulting in the disappearance of the ravine as such. Highways were laid on the territory of Babyn Yar, and a residential area and a park were built. The area has changed so much that even historians argued about the exact location of the mass executions.</p>
    
            <p>In order to help better understand the important historical events of Babyn Yar, this  project reconstructs the landscape where those events happened.</p>
    
            <iframe width="100%" height="600" src="https://www.youtube-nocookie.com/embed/J8LsLWtRLcw?si=DE3eG6p9DjkyJKhP" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
    
            <p class="figure-text">Babyn Yar Models presentation video (Center for Spatial Technologies 2021)</p>
    
            <h3 id="image-match-guide">Guide overview</h3>
    
            <p>This guide outlines the general methodology for reconstructing a historical landscape using a variety of media sources. These sources include archival drawings, maps, aerial and satellite photographs, as well as ground-level photographs and videos. The guide describes the processes and techniques used to work with diverse data types – such as topographic maps and photogrammetry – to build a spatial model of a transformed landscape.</p>
    
            <p>We published a damage map based on our radar data analysis in the New York Times on 3 November 2023 (<a href="https://static01.nyt.com/images/2023/11/03/nytfrontpage/scan.pdf" target="_blank">https://static01.nyt.com/images/2023/11/03/nytfrontpage/scan.pdf</a>). In less than a month of war, our analysis showed that over a quarter of buildings in North Gaza had already been damaged. Following this publication, we started receiving requests for the damage data from journalists and humanitarians. Now, with each new assessment, we email maps of new and cumulative damage and a brief summary of damage statistics and trends to nearly 200 journalists and humanitarians across 90 organizations for uptake into their reporting or analysis. There has been broad uptake of the damage maps by different users, with an amazing array of creative, impactful reporting in the nearly 300 news articles that have used our maps (<a href="https://docs.google.com/spreadsheets/d/1_XVQx97hH3n31XPoYimmIstnZUhof8a5Z5rt3Z2VZg4/edit?usp=drivesdk" target="_blank">https://docs.google.com/spreadsheets/d/1_XVQx97hH3n31XPoYimmIstnZUhof8a5Z5rt3Z2VZg4/edit?usp=drivesdk</a>).</p>
    
            <p>As we began distributing the damage maps to a broader group of recipients, we realized the need to clearly communicate the appropriate use cases as well as limitations of the damage maps. For example, we state that the damage maps are “intended for visualization/cartography but are not intended for analytical (quantitative and/or spatially explicit) comparisons with other data such as population or building footprints.” We also share a slightly coarsened version of our damage maps that precludes identification of specific buildings that may have been damaged or destroyed. We caution users that a small portion of new damage in a given date’s analysis may not be confirmed again. These ephemeral changes may look like damage in our analysis but instead could result from seasonal changes in vegetation unassociated with the war, the deposition of dust, or the clearing of debris. Since ephemeral changes are not (re-)detected in later imagery, we remove them from subsequent maps of cumulative damage.</p>
    
            <p>Other damage assessments of the Gaza Strip have been published using different remote sensing techniques, and we have sought to understand reasons for agreement or disagreement in the extent and timing of damage. Chief among these is the pseudo-monthly damage dataset produced by the United Nations Operational Satellite Program, or UNOSAT (e.g. <a href="https://unosat.org/products/3904" target="_blank">https://unosat.org/products/3904</a>). UNOSAT urban damage assessments are based on expert visual interpretation of very-high resolution (usually a half-meter or less) satellite imagery. UNOSAT analysts place points at locations of evident damage and assign a grade of damage severity. UNOSAT and any other damage dataset based on aerial or satellite imagery that looks at earth from a bird’s eye view above will be well suited to identify damage to rooftops but may miss damage to the sides of buildings. Radar, like the Sentinel-1 system that we use, is “side looking” and sees the world from an angle, giving it theoretically greater sensitivity to lateral damage along a building’s exterior.</p>
    
            <p>Differences in damage maps from two different approaches are inevitable but should be explainable. Agreement assessments between different damage maps can be performed in many ways; we use four types of agreement metrics. </p>
            
            <p style="padding-left: 3em; text-indent: -3em;">&emsp;&emsp;●  True positive and true negative are the most direct in that they are examples of agreement between the presence (positive) or absence (negative) of “damage” in one dataset compared to another. In most cases, we aspire to have high rates of true positives and true negatives, expressing general agreement both where damage is and isn’t found.</p>
    
            <p style="padding-left: 3em; text-indent: -3em;">&emsp;&emsp;●  A false positive, on the other hand, occurs where damage is reported in one dataset that is not detected in a reference dataset. False positives could occur because a detection approach is too generous with its damage detection and may need additional constraints to limit over-detection of damage in places with insufficient evidence of damage.</p>
    
            <p style="padding-left: 3em; text-indent: -3em;">&emsp;&;●  A false negative occurs where an approach does not detect damage that is reported in a reference dataset. Perhaps an approach is too restrictive in what it considers to be ‘damage’ and excludes legitimate locations of damage.</p>
    
            <p>A challenge we face in using these metrics when comparing our damage maps to those made by UNOSAT or any other group is that these metrics assume that the approaches are sensitive to the same thing: building damage. But we know that the overhead view adopted by UNOSAT excludes lateral damage to the building, and we also know that the side-looking radar may have its view of lateral damage occluded by neighboring buildings. There are many differences due to spatial resolutions of imagery, dates of imagery used, and sensitivity to severity of damage, among others that we know matter but whose impact on the level of agreement has not yet been examined in detail.</p>
    

    
        </div>
        
    </div>
</div>

    <script>
        let tutorialsData;
        let colorsData;

        function loadData() {
            // Load both JSON files
            d3.json("../tutorials.json").then(function(loadedData) {
                tutorialsData = loadedData;
                d3.json("../colors.json").then(function(loadedColors) {
                    colorsData = loadedColors;
                    displayTagsAndPanel();
                });
            });
        }

        function getColorForTag(tag) {
            // Find the panel color for a given tag
            const colorEntry = colorsData.colors.find(colorEntry => colorEntry.tags.includes(tag));
            return colorEntry ? colorEntry.color : "#CCCCCC"; // Default to grey if not found
        }

        function getPanelColor(panel) {
            // Find the color for a given panel
            const colorEntry = colorsData.colors.find(colorEntry => colorEntry.panel === panel);
            return colorEntry ? colorEntry.color : "#CCCCCC"; // Default to grey if not found
        }

        function displayTagsAndPanel() {
            const projectName = document.body.getAttribute("data-project-name");
            const tagContainer = document.getElementById("project_tags");
            const panelTextElement = document.getElementById("panel-text");
            const circleElement = document.querySelector(".tutorials-circle");

            const project = tutorialsData.tutorials.find(tutorial => tutorial.project === projectName);

            if (project) {
                panelTextElement.innerText = project.panel;

                // Find and set the color for the panel
                const panelColor = getPanelColor(project.panel);
                circleElement.style.backgroundColor = panelColor;

                // Display and color the tags
                project.tags.forEach(tag => {
                    const tagElement = document.createElement("div");
                    tagElement.className = "tag-item";
                    tagElement.innerText = tag;
                    tagElement.style.backgroundColor = getColorForTag(tag); // Use color for each tag
                    tagContainer.appendChild(tagElement);
                });
            }
        }

        document.getElementById('sidePanel').addEventListener('click', function() {
            window.location.href = '../index.html'; 
        });

        loadData(); // Call the loadData function to load the JSON and display the tags and panel text
    </script>
</body>

</html>