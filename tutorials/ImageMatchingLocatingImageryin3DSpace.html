<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image-matching: Locating Imagery in 3D Space</title>
    <link rel="stylesheet" href="../main.css">
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@300&display=swap" rel="stylesheet">
    <script src="https://www.gstatic.com/charts/loader.js"></script>
    <script src="https://code.jquery.com/jquery-1.12.4.js"></script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-J2SEN9LXNV"></script>
    <script src="https://d3js.org/d3.v6.min.js"></script>



    <link rel="stylesheet" href="/path/to/styles/default.css"/>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <!-- and it's easy to individually load additional languages -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/go.min.js"></script>

    <script>hljs.highlightAll();</script>
    <script src="/path/to/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

</head>

<body data-project-name="Image Matching: Locating Imagery in 3D Space"> <!-- The name here is to link Tags from json file (project name)-->
    <div class="top-bar">
   
        <div class="title">
            <a href="../index.html" id="sidePanel">
                Methods and Tutorials in Spatial Research 
            </a>
        </div>

        <div class="button-container" id="about">
            <a href="../about.html">About</a>
        </div>
     </div>
     
<div class="column">
    <div class="column-left">
        <div id="tutorials-side-panel">
            <h6>
                Currently viewing tutorial page, <br><a href="../index.html">click here to return to main page.</a>
            </h6>

            <h3>Workshop Panel: </h3>
            <div class="visual-code-container">
                <div class="tutorials-circle"></div>
                <p id="panel-text"></p>
            </div>
            <h3>Project Tags: </h3>
            <div class="tutorials-ProjectTagsContainer" id="project_tags">
                <!-- Tags will be dynamically inserted here -->
            </div>
        </div>
    </div>
    <div class="column-main">
        <div class="tutorials-section">
        
            <h1>Image-matching: Locating Imagery in 3D Space</h1>
            <h2>Maksym Rokmaniko, The Center for Spatial Technologies</h2>
            <!-- project: https://spatialtech.notion.site/Image-matching-Locating-Imagery-in-3D-Space-113bc6e1b0978028b5c5d630ad9b7a00#113bc6e1b0978058b7ebec8340aa2bec</p> -->

            <h4>Jump to:</h4>

            <a href="#setup" style="margin-bottom: 0%;">Part 1: Setup</a>: 
                    <a href="#software">Software Requirements</a> | <a href="#downloads">Data Downloads</a></p>
            <a href="#base-model">Part 2: Building the Base Model</a>:
                <p class="indent">
                    <a href="#DEM">Creating a Base Model with DEM and Satellite Imagery</a><br>
                    <a href="#coordinates">Setup project coordinate system</a> |
                    <a href="#GISmodel">Export GIS data for model</a> | 
                    <a href="#blender-model">Building Mesh model with Blender</a> | 
                    <a href="#base-model">Alternative Methods to Build the Base Model</a>
                </p>

            <a href="#image-match">Part 3: Image-Matching</a>:
                    <a href="#image-camera">Solve Static Image camera position</a> | <a href="#troubleshoot">Troubleshooting a Bad Match</a>

            <p class="image">
                <img src="./images/imageMatching/main.png" alt="tutorial-main-image" style="margin-bottom: 0%;">
                <p class="image-text" style="margin-top: -40px;">© Center for Spatial Technologies</p>
            </p>
    
            <p>In this tutorial, we'll explore how to use the <a href="https://github.com/sptch/image-matcher/tree/main">image-matcher Blender add-on</a> to locate 2D images within a 3D model. This technique is crucial for our ongoing work at the <a href="https://www.spatialtech.info/en">Center for Spatial Technologies</a>, where we've applied it to various projects.</p>
    
            <p>We've used and evolved this method to document and analyze sites of significant historical and current events, including:</p>
    
            <a class="indent" href="https://www.spatialtech.info/en/works/by-models" target="_blank">• Babyn Yar</a><br>
            <a class="indent" target="_blank" href="https://www.spatialtech.info/en/works/tv-tower">• Russian attack on Kyiv TV tower</a><br>
            <a class="indent" target="_blank" href="https://www.spatialtech.info/en/works/mykolaiv">• Missile strike on Mykolaiv ODA</a><br>
            <a class="indent" target="_blank" href="https://theater.spatialtech.info/en">• Mariupol Drama Theater</a>
    
            
            <p style="font-style: italic; background-color: #f0f0f0; padding: 20px;">
                * Currently, CST team applying this technique to the Chersonesus archaeological site in occupied Crimea. <a href="https://whc.unesco.org/en/list/1411/">This UNESCO World Heritage Site</a> is being manipulated for Russian national myth-building, with rushed construction and ideologically-driven excavations causing irreversible damage. *

                <br><br>

                * By precisely positioning photographs and drone footage in a 3D model, we can document these changes, providing vital evidence of cultural heritage destruction. In this tutorial we will learn to create a base 3D terrain model, match various imagery types to it, and create animations between matched positions. While we use Chersonesus as our case study, these skills can be applied to any site requiring accurate documentation and analysis. * 
            </p>
                
            
            <h3 id="setup">Setup</h3>

            <h4 id="software">Software Requirements</h4>
            
            <p>To follow this tutorial, you'll need to have the following software installed:</p>
            <p class="indent">1. <b>Blender</b> (version 3.0 or newer): Blender is a free and open-source 3D creation suite. Download it from blender.org. We will use Blender 4.2.</p>
            <p class="indent">2. <b>Image-matcher Add-on for Blender</b>: This custom add-on enables precise image matching in Blender. You can download it from our <a href="https://github.com/sptch/image-matcher/tree/main">GitHub repository.</a></p>
            <p class="indent">3. <b>Blender-GIS add-on for Blender</b>: This add-on enables the import and manipulation of geospatial data in Blender. Download it from the <a href="https://github.com/domlysz/BlenderGIS">BlenderGIS GitHub repository.</a></p>
            <p class="indent">4. <b>QGIS</b> (latest stable version): QGIS is a free and open-source geographic information system. Download it from <a href="https://qgis.org/en/site/forusers/download.html">qgis.org.</a></p>

            <p>
                Ensure all software is installed and functioning correctly before beginning the tutorial. If you encounter any issues with installation or setup, please refer to the documentation for each software.
            </p>
            
            <h4 id="downloads">Data Downloads</h4>

            <p>For this tutorial, you'll need several types of geospatial data to create a 3D model and match 2D images to it. Download the following datasets:</p>

            <p class="indent">1. <b>ALOS PALSAR Radiometric Terrain Corrected (RTC) Data</b>: This high-resolution digital elevation model (DEM) is derived from radar data. Source: <a href="https://search.asf.alaska.edu/#/?dataset=ALOS">Alaska Satellite Facility (ASF) Data Search.</a></p>
            <p class="indent">2. <b>High-resolution Satellite Imagery</b>: Recent high-resolution imagery of your study area.</p>
            <p class="indent">3. <b>Drone Footage</b>: Aerial imagery captured by drones over your study area.</p>
            <p class="indent">4. <b>Ground-level Photographs</b>: Photographs taken at ground level of key areas in your study site.</p>
            <p class="indent">5. <b>Photogrammetry Model</b> (optional): A detailed 3D model of specific structures within your study area.</p>

            <p>
                To make it easier to follow along with this tutorial, we've prepared a sample dataset that includes all necessary files for the Chersonesus site. You can download this dataset here:
            </p>
            <p>
                Download Sample Dataset (sample_image-match_data.zip)
            </p>

            <h3 id="base-model">Building the Base Model</h3>

            <p>
                In this tutorial, we will demonstrate the use of the <a href="https://github.com/sptch/image-matcher/tree/main">Image-Matcher Add-on for Blender</a> by using the example of aerial photographs around a large-scale archaeological site. This technique can be applied in various contexts and across different model scales, including architectural, interior, and object models.
            </p>
            <p>
                If your primary interest is learning how to use the Image Matcher tool, you can skip the section on building the base model, directly towards <a href="#image-match"></a>Image-matching</a>, as this is only one possible use case for the tool. The add-on is versatile and can be applied to a wide range of scenarios, enabling precise image alignment and location on both small and large-scale models.
            </p>

            <h4 id="DEM">Creating a Base Model with DEM and Satellite Imagery</h4>

            <p>
                A <b>Digital Elevation Model (DEM)</b> provides essential elevation data for 3D terrain modeling. <br>
                Several options for obtaining DEM data, depending on your project’s location and requirements:
            </p>
            <p>
                1. <b>Provided DEM for Chersonesus</b>: You can use the provided .tif file for the Chersonesus site, which contains high-resolution elevation data for the area.
            </p>

        
        <div class="image">
            <img src="./images/imageMatching/image1.webp" alt="DEM">
        </div>

            <p>
                2. <b>ALOS PALSAR DEM</b>: For other regions or more detailed elevation data, you can download high-resolution DEMs from the <b>Alaska Satellite Facility (ASF)</b>. Go to <a href="https://search.asf.alaska.edu/#/?dataset=ALOS">ASF Data Search</a>, select the <b>Hi-Res Terrain Corrected</b> data, and download the .tif file for your area of interest.
            </p>
            
            <div class="image">
            <img src="./images/imageMatching/image2.webp" alt="DEM">
            </div>
            
            <p>
                3. <b>Mapzen Terrain Tiles</b>: As an alternative, you can use the <a href="https://www.mapzen.com/blog/terrain-tile-service/">Mapzen Terrain Tiles</a> dataset, a public source for global elevation data. This tiled dataset offers lower-resolution but easily accessible DEMs, which can be added to QGIS via XYZ-tile connection. Simply configure the URL (<a href="https://s3.amazonaws.com/elevation-tiles-prod/terrarium/{z}/{x}/{y}.png">https://s3.amazonaws.com/elevation-tiles-prod/terrarium/{z}/{x}/{y}.png</a>) in the XYZ-tile connection dialog in QGIS to load global elevation tiles.
            </p>

        <div class="image-fullwidth">

            <div class="image-fullwidth-50">
                <img src="./images/imageMatching/image3.webp" alt="DEM">
                <p class="image-text">
                    Mapzen Terrain Tiles (<a href="https://elevation-tiles-prod.s3.amazonaws.com/index.html#3/0.09/-0.09">  Public Dataset</a>)
                </p>
            </div>

            <div class="image-fullwidth-50">
                <img src="./images/imageMatching/image4.webp" alt="DEM">
                <p class="image-text">QGIS XYZ-tiles connection configuration</p>
            </div>

        </div>

            <p>
                When using <b>satellite imagery</b>, select images captured as close to nadir (directly overhead) as possible. This approach minimizes distortions, especially in areas with varied terrain, reducing the need for complex orthorectification and ensuring a more accurate 3D landscape representation.
            </p>


            <div class="image-fullwidth">
                <div class="image-fullwidth-100">
                    <img src="./images/imageMatching/image5.webp" alt="DEM">
                </div>
            </div>
            <p class="image-text">Evaluating satellite imagery for base model texture</p>
            

            <p>
                When evaluating satellite imagery for your model, consider the terrain’s impact on image quality:
            </p>
            <p class="indent">1. <b>Poor Quality</b>: Significant terrain relief causes noticeable distortions. Steep slopes and tall structures may appear skewed or stretched.</p>
            <p class="indent">2. <b>Acceptable Quality</b>: Less terrain influence, but some distortion still visible on slopes and taller objects.</p>
            <p class="indent">3. <b>Ideal Quality</b>: Minimal terrain-induced distortion. The image appears flattened, with vertical elements and slopes accurately represented.</p>

            <p>
                Select and import your satellite imagery into QGIS
            </p>

            <p>
                With the Digital Elevation Model (DEM) and satellite imagery layers prepared, we are ready to proceed to the next step: building the geometry. This step will involve overlaying the DEM with the satellite imagery to create a textured 3D model, accurately reflecting the terrain’s historical features.
            </p>

            <div class="image-fullwidth">
                <div class="image-fullwidth-50">
                    <img src="./images/imageMatching/image6.webp" alt="DEM">
                    <p class="image-text">Heracles Peninsula DEM tileset. @Mapzen tiles, 2024
                    </p>
                </div>
                <div class="image-fullwidth-50">
                <img src="./images/imageMatching/image7.webp" alt="DEM">
                <p class="image-text">Heracles Peninsula Satelite image. @Google Earth, 2022
                </p>
                </div>
                
            </div>

            <h3 id="coordinates">Setup project coordinate system</h3>

            <p>
                For this image-matching tool tutorial, we'll focus on the Ancient City of Tauric Chersonese site and its buffer protected zone.
            </p>
            <div class="image">
                <img src="./images/imageMatching/image8.webp" alt="DEM">
            </div>
            <p class="image-text">The Ancient City of Tauric Chersonese and its buffer zone
            </p>

            <p>
            When zooming in on a particular site, we recommend defining a local coordinate system for 3D modeling and coordination. While optional, we prefer to derive an offset local <b>coordinate reference system (CRS)</b> from the defined regional one. In this case, we'll use <code>UCS-2000 / 3-degree Gauss-Kruger zone 11</code> as the CRS for this area.
            </p>

            <p>
                We'll define a 2000x2000 meter square domain for our model, with a user coordinate system <code>UCS-2000 / Chersonese</code> originating in the square's bottom-left corner.
            </p>

            <div class="image-fullwidth">
                <div class="image-fullwidth-50">
                    <img src="./images/imageMatching/image9.png" alt="DEM">
                    <p class="image-text">Define Custom CRS</p>

                    <img src="./images/imageMatching/image10.png" alt="DEM">
                    <p class="image-text">Select User-Defined or suitable general CRS for your geographic area
                    </p>

                </div>

                <div class="image-fullwidth-50" style="margin-left:5%">
                    <!-- <pre><code class="language-html">...</code></pre> -->
                <pre style="background-color:white;" class="language-html"><code >
    PROJCRS["UCS-2000 / Chersonese",
    BASEGEOGCRS["UCS-2000",
        DATUM["Ukraine 2000",
            ELLIPSOID["Krassowsky 1940",6378245,298.3,
                LENGTHUNIT["metre",1]]],
        PRIMEM["Greenwich",0,
            ANGLEUNIT["degree",0.0174532925199433]],
        ID["EPSG",5561]],
    CONVERSION["3-degree Gauss-Kruger zone 11",
        METHOD["Transverse Mercator",
            ID["EPSG",9807]],
        PARAMETER["Latitude of natural origin",0,
            ANGLEUNIT["degree",0.0174532925199433],
            ID["EPSG",8801]],
        PARAMETER["Longitude of natural origin",33,
            ANGLEUNIT["degree",0.0174532925199433],
            ID["EPSG",8802]],
        PARAMETER["Scale factor at natural origin",1,
            SCALEUNIT["unity",1],
            ID["EPSG",8805]],
        PARAMETER["False easting",-38220,
            LENGTHUNIT["metre",1],
            ID["EPSG",8806]],
        PARAMETER["False northing",-4940800,
            LENGTHUNIT["metre",1],
            ID["EPSG",8807]]],
    CS[Cartesian,2],
        AXIS["northing (X)",north,
            ORDER[1],
            LENGTHUNIT["metre",1]],
        AXIS["easting (Y)",east,
            ORDER[2],
            LENGTHUNIT["metre",1]],
    USAGE[
        SCOPE["Heritage site violations documentation, high-precision surveying, and 3D modeling of Tauric Chersonese."],
        AREA["Ukraine, Crimia. Ancient City of Tauric Chersonese."],
        BBOX[44.60, 33.48,44.62, 33.51]]]
                    </code></pre>
                <p class="image-text"><code>UCS-2000 / Chersonese</code> CRS definition</p>
                </div>

            </div>

            <p>
                Using this local coordinate system allows for easy conversion between local Blender model data and world/GIS contexts.
            </p>

            <h3 id="GISmodel">Export GIS data for model</h3>
            <h4>Create an area of interest (AOI) polygon</h4>
            <p>
                Before clipping the DEM and satellite imagery, you need to define the <b>Area of Interest (AOI)</b>. Follow these steps to create an AOI polygon:
            </p>
            <p>
                1. <b>Create a New Shapefile Layer (Vector Layer):</b>
            </p>
            <p class="indent">
                •   In QGIS, go to the top menu and select <code>Layer > Create Layer > New Shapefile Layer…</code><br>
                •   In the dialog box, choose <b>Polygon </b>as the geometry type.<br>
                •   Set the CRS to your custom CRS (or the regional CRS).<br>
                •   Name the file (e.g., 2000.shp) and save it.
            </p>
  
            <p>
                2. <b>Draw the AOI Polygon:</b>
            </p>
            <p class="indent">
                    •   Select the <b>Toggle Editing</b> button for the new shapefile layer in the Layers panel.<br>
                    •   Click the <b>Add Polygon Feature</b> tool from the toolbar.<br>
                    •   Draw a rectangle covering your 2000x2000m area of interest by clicking on the map canvas or using advanced digitizing tools.<br>
                    •   Press <b>Enter or Right Click</b> to finish the polygon and save the shapefile.    
            </p>
            <p>
                3. <b>Save and Exit Editing Mode:</b>
            </p>
            <p class="indent">
                •   After drawing the polygon, click Toggle Editing again, and choose Save when prompted.
            </p>

            <h4>Clip and export selected layers</h4>
            <p>There are two option we can save clipped region:</p>
            <p class="indent">
                1. Clipping raster <code>Raster > Extraction > Clip Raster by Mask Layer. </code> <br>
                2. Export layer with clipping boundaries <code>Right-Click on the Raster Layer in the Layers Panel > Select “Export” > “Save As…”</code>
            </p>

            <p>
                While the “<b>Clip Raster by Mask Layer</b>” method generally offers better precision and higher quality, we recommend using it for most clipping tasks. However, when working with raster tiles, this method may not be supported. In such cases, we suggest using the <b>“Export” > “Save As”</b> option, which is more suitable for clipping tiled datasets or formats that don’t allow the use of the “Clip Raster by Mask Layer” tool.
            </p>

            <div class="image-fullwidth">
                <div class="image-fullwidth-50">
                    <img src="./images/imageMatching/image11.png" alt="DEM">
                    <p class="image-text">Clip Raster by Mask Layer. Properties for TIFF-souce layer </p>
                </div>

                <div class="image-fullwidth-50">
                    <img src="./images/imageMatching/image12.png" alt="DEM">
                    <p class="image-text">“Export” > “Save As”. Properties for XYZ-raster-tiles-source layer.</p>
                </div>
            </div>
            <div class="image-fullwidth">
                <div class="image-fullwidth-100">
                    <img src="./images/imageMatching/image13.png" alt="DEM">
                    <p class="image-text">Exported Satellite and DEM raster.</p>
                </div>
            </div>

    <h3 id="blender-model">Building Mesh model with Blender</h3>

        <p> 
            Now that we have DEM and satellite imagery prepared, we can start building a 3D mesh model using Blender and the BlenderGIS add-on.
        </p>

        <p class="indent-num">
            1. Start new blender project (<a href="https://github.com/domlysz/BlenderGIS/wiki/Install-and-usage">don't forget to download, activate and configure Blender GIS plugin</a>). <br>
            Setup custom CRS with Proj4 string:
        </p>
        <p class="indent">
        <code style="color:black">
            +proj=tmerc +lat_0=0 +lon_0=33 +k=1 +x_0=-38220 +y_0=-4940800 +ellps=krass +units=m +no_defs +type=crs
        </code>
        </p>
        <p class="image">
            <img src="./images/imageMatching/image14.png" alt="mesh1">
            
        </p>

        <p class="indent-num">
            2. Build mesh using <code>GIS > Import > Georeferenced raster </code> <br>
            • Mode - DEM as displacement texture<br>
            • Subdivision - Subsurf<br>
            • Smooth relief = TRUE<br>
            • CRS - pick custom CRS
        </p>

        <p class="image">
            <img src="./images/imageMatching/image15.png" alt="mesh2">
            <p class="image-text">Load DEM as base texture for building mesh model</p>
        </p>

        <p class="indent-num">
            3. While we have model loaded and generated, we can adjust sharpness increasing or decreasing Subdivision Levels from <code>Select Mesh > Modifiers > Subdivision Surface properties > Levels Viewport/Render </code>
        </p>

        <p class="image">
            <img src="./images/imageMatching/image16.png" alt="mesh2">
            <p class="image-text">Control model sharpness</p>
        </p>

        <p class="indent-num">
            4. Check Georeference:<br>
            • Go to <code>3D View > View > Geoscene > Scene Georeferencing.</code><br>
            • Set the CRS to your custom CRS.<br>
            • Set <code>X=0</code> and <code>Y=0</code> to match the Blender scene’s origin to your custom CRS.<br>
            • Smooth relief = TRUE<br>
            • If you’re using a global or regional CRS, you can configure offsets to ensure alignment between your 3D model and the GIS data.
        </p>
        <p class="image">
            <img src="./images/imageMatching/image17.png" alt="mesh2">
            <p class="image-text">Configure Blender ↔ CRS offset</p>
        </p>

        <p class="indent-num">
            5. Load satellite imagery georaster as mesh texture basemap using <code>GIS > Import > Georeferenced raster</code> :<br>
            • Mode - Basemap on mesh<br>
            • Object - <b>Provide mesh</b><br>
        </p>
        <p class="image">
            <img src="./images/imageMatching/image18.png" alt="mesh2">
            <p class="image-text">
                Load satellite imagery georaster as mesh texture basemap   
            </p>
        </p>
        <p class="image">
            <img src="./images/imageMatching/image19.png" alt="mesh2">
            <p class="image-text">
                Textured 3D model
        </p>

        <h4 id="base-model">Alternative Methods to Build the Base Model</h4>
        <p>
            For users who don’t require highly precise georeferencing, configuring custom CRS or who need a faster workflow, there are other methods to create a 3D base model:
        </p>
        <p class="indent-num">
            1. <a href="https://github.com/domlysz/BlenderGIS/wiki/SRTM">BlenderGIS with SRTM and Google Basemap Data:</a><br>
            • If high-resolution DEMs aren’t needed, you can use BlenderGIS to import SRTM data directly within Blender. This method is faster but less accurate.
        </p>
        <p class="indent-num">
            2. <a href="https://speckle.systems/tutorials/create-3d-context-map-with-qgis-and-speckle/">Create 3D Context Maps with QGIS and Speckle </a><br>
            • Similar to QGIS→Blender workflow, but use Speckle as geometry processor and storage.
        </p>

        <h3 id="image-match">
            Image-Matching
        </h3>
        <p>
            Image matching aligns 2D images to a 3D model using the <b>Perspective-n-Point (PnP)</b> method. This approach determines camera <b><i>extrinsics</i></b> (position and orientation) and ***intrinsics*** (lens characteristics like focal length and distortion).
        </p>

        <p>
            <b>PnP</b> works by matching multiple 2D points with their corresponding 3D points. Solving these relationships allows us to determine the camera's 3D position and estimate internal parameters.
        </p>
        <p>
            To solve camera extrinsics with known focal length, you need at least <b>4 points</b>. If you want to automatically determine the focal length, optical center, and lens distortion (camera intrinsics), you need at least <b>6 points</b>. For more details, see <a href="https://docs.opencv.org/4.x/d5/d1f/calib3d_solvePnP.html">OpenCV's solvePnP</a> and <a href="https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html">OpenCV`s camera calibration documentation</a>.
        </p>

        <h4 id="image-camera">
            Solve Static Image camera position
        </h4>
        <p class="indent-num">
            1. <b>Install the Image-matcher Blender add-on</b> following the <a href="https://github.com/sptch/image-matcher/blob/main/docs/installation.md">initial instructions</a>.
        </p>
        <p class="indent-num">
            2. <b>Split the Blender screen</b> by dragging the top left corner of the 3D view until the mouse cursor turns into a cross. Click and drag to the right to create a split-screen. This allows you to view both the 2D image and 3D model side by side.
        </p>
        <p class="image">
            <img src="./images/imageMatching/image20.png" alt="mesh2">
            <p class="image-text">
                Split Blender screen
            </p>
        </p>

        <p class="indent-num">
            3. <b>Change the Window editor type</b> to 'Movie Clip Editor' for one of the windows you created. Click on the icon in the top left corner of the newly split screen, and select 'Movie Clip Editor'.
        </p>
        <p class="image">
            <img src="./images/imageMatching/image21.png" alt="mesh2">
            <p class="image-text">
                Change Window editor type to Movie Clip Editor
            </p>
        </p>

        <p class="indent-num">
            4. <b>Add Image</b> Go to <code>Image Match > Define Image Filepath > pick image and click Accept > Click Add Image</code>
        </p>
        <p class="image">
            <img src="./images/imageMatching/image22.png" alt="mesh2">
            <p class="image-text">
                Select and load Image
            </p>
        </p>
        <p class="indent-num">
            5. <b>Pick 3D Model and Select Points</b> <br>

        </p>
        <p class="indent">
            • Go to the <b>Points Tab</b> > Use the dropdown to select your 3D model or click the eyedropper icon to pick it directly in the 3D viewport. <br>
            • In <b>Point Mode</b>, left-click in the 2D image to add a point, and then select the corresponding point on the 3D model in the 3D viewer.<br>
            • Repeat this process until you have at least <b>6 pairs</b> of points (or <b>4 pairs</b> if you know the focal length or plan to adjust it manually).<br>
            • Ensure that the points are distributed across the entire image plane for better accuracy. To exit <b>Point Mode</b>, right-click or press <b>Esc</b>.<br>
        </p>
        <div class="image-fullwidth">
            <div class="image-fullwidth-50">
                <p class="image">
                <img src="./images/imageMatching/image23.png" alt="mesh2">
                <p class="image-text">
                    Pick 3D Model
                </p>
            </p>    
            </div>
            <div class="image-fullwidth-50">
            <p class="image">
                <img src="./images/imageMatching/image24.png" alt="mesh2">
                <p class="image-text">
                    Select corresponding points pairs
                </p>
            </p>
            </div>
        </div>
            <p class="indent-num">
                6. <b>Camera Calibration (PNP-Calibrate Camera Tab)</b><br>
            </p>
            <p class="indent">
                • Calibrate the camera settings (e.g., focal length) using <b>OpenCV</b>.<br>
                • If you know the focal length, input it directly. Otherwise:<br>
                    ⸰ Tick <b>Focal Length</b> and click <b>Calibrate Camera</b>.<br>
                    ⸰ Check <b>Reprojection Error</b>; lower values are better.
                </p>
            </p>
            <p class="indent-num">
                7. <b>Solve Camera Pose (PNP-Solve Pose Tab)</b><br>
            </p>
            <p class="indent">
                • Click <b>Solve Camera Pose</b> to calculate the camera's position and orientation.<br>
                • Use <b>Toggle Camera View</b> to see the match.<br>

                    ⸰ Adjust image opacity and toggle the 2D image for better visualization.
            </p>
            </p>
            <p class="image">
                <img src="./images/imageMatching/image25.png" alt="mesh2">
                <p class="image-text">
                    Calibrate and solve camera
                </p>
            </p>

            <p>
                8. <b>Add more images</b><br>
                • Switch between images by clicking the blue highlighted icon next to their names.

            </p>
            <div class="image-fullwidth">
                <div class="image-fullwidth-100">
                    <img src="./images/imageMatching/image26.png" alt="mesh2">
            </div></div>
            <h4 id="troubleshoot">
                Troubleshooting a Bad Match
            </h4>
            <p>
                • <b>Check Point Pairs</b>: Ensure points are accurately placed in both the 2D and 3D <br>
                • <b>Spread Points Evenly</b>: If the match is bad in specific areas, add more points there.<br>

                • <b>Recalibrate Camera</b>: Click <b>Reset Camera</b>, then <b>Calibrate Camera</b> again, and re-solve the pose. 
            </p>









    
        </div>
        
    </div>
</div>

    <script>
        let tutorialsData;
        let colorsData;

        function loadData() {
            // Load both JSON files
            d3.json("../tutorials.json").then(function(loadedData) {
                tutorialsData = loadedData;
                d3.json("../colors.json").then(function(loadedColors) {
                    colorsData = loadedColors;
                    displayTagsAndPanel();
                });
            });
        }

        function getColorForTag(tag) {
            // Find the panel color for a given tag
            const colorEntry = colorsData.colors.find(colorEntry => colorEntry.tags.includes(tag));
            return colorEntry ? colorEntry.color : "#CCCCCC"; // Default to grey if not found
        }

        function getPanelColor(panel) {
            // Find the color for a given panel
            const colorEntry = colorsData.colors.find(colorEntry => colorEntry.panel === panel);
            return colorEntry ? colorEntry.color : "#CCCCCC"; // Default to grey if not found
        }

        function displayTagsAndPanel() {
            const projectName = document.body.getAttribute("data-project-name");
            const tagContainer = document.getElementById("project_tags");
            const panelTextElement = document.getElementById("panel-text");
            const circleElement = document.querySelector(".tutorials-circle");

            const project = tutorialsData.tutorials.find(tutorial => tutorial.project === projectName);

            if (project) {
                panelTextElement.innerText = project.panel;

                // Find and set the color for the panel
                const panelColor = getPanelColor(project.panel);
                circleElement.style.backgroundColor = panelColor;

                // Display and color the tags
                project.tags.forEach(tag => {
                    const tagElement = document.createElement("div");
                    tagElement.className = "tag-item";
                    tagElement.innerText = tag;
                    tagElement.style.backgroundColor = getColorForTag(tag); // Use color for each tag
                    tagContainer.appendChild(tagElement);
                });
            }
        }

        document.getElementById('sidePanel').addEventListener('click', function() {
            window.location.href = '../index.html'; 
        });

        loadData(); // Call the loadData function to load the JSON and display the tags and panel text

        // first, find all the div.code blocks
            document.querySelectorAll('div.code').forEach(block => {
            // then highlight each
            hljs.highlightBlock(block);
            });
    </script>
</body>

</html>