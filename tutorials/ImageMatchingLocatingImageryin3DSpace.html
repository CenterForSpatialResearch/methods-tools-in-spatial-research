<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Matching: Locating Imagery in 3D Space</title>
    <link rel="stylesheet" href="../main.css">
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@300&display=swap" rel="stylesheet">
    <script src="https://www.gstatic.com/charts/loader.js"></script>
    <script src="https://code.jquery.com/jquery-1.12.4.js"></script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-J2SEN9LXNV"></script>
    <script src="https://d3js.org/d3.v6.min.js"></script>
    <link rel="stylesheet" href="/path/to/styles/default.css"/>
    <script src="/path/to/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

</head>

<body data-project-name="Image Matching: Locating Imagery in 3D Space"> <!-- The name here is to link Tags from json file (project name)-->
    <div class="top-bar">
   
        <div class="title">
            <a href="../index.html" id="sidePanel">
                Methods and Tutorials in Spatial Research 
            </a>
        </div>

        <div class="button-container" id="about">
            <a href="../about.html">About</a>
        </div>
     </div>
     
<div class="column">
    <div id="tutorials-side-panel">
        <h6>
            Currently viewing tutorial page, <br><a href="../index.html">click here to return to main page.</a>
        </h6>

        <h3>Workshop Panel: </h3>
        <div class="visual-code-container">
            <div class="tutorials-circle"></div>
            <p id="panel-text"></p>
        </div>
        <h3>Project Tags: </h3>
        <div class="tutorials-ProjectTagsContainer" id="project_tags">
            <!-- Tags will be dynamically inserted here -->
        </div>
    </div>
    <div class="column-main">
        <div class="tutorials-section">
        
            <h1>Image-matching: Locating Imagery in 3D Space</h1>
            <h2>Maksym Rokmaniko, The Center for Spatial Technologies</h2>
            <!-- project: https://spatialtech.notion.site/Image-matching-Locating-Imagery-in-3D-Space-113bc6e1b0978028b5c5d630ad9b7a00#113bc6e1b0978058b7ebec8340aa2bec</p> -->
    
            <p>In this tutorial, we'll explore how to use the <a href="https://github.com/sptch/image-matcher/tree/main">image-matcher Blender add-on</a> to locate 2D images within a 3D model. This technique is crucial for our ongoing work at the <a href="https://www.spatialtech.info/en">Center for Spatial Technologies</a>, where we've applied it to various projects.</p>
    
            <p>We've used and evolved this method to document and analyze sites of significant historical and current events, including:</p>
    
            <a class="indent" href="https://www.spatialtech.info/en/works/by-models" target="_blank">• Babyn Yar</a><br>
            <a class="indent" target="_blank" href="https://www.spatialtech.info/en/works/tv-tower">• Russian attack on Kyiv TV tower</a><br>
            <a class="indent" target="_blank" href="https://www.spatialtech.info/en/works/mykolaiv">• Missile strike on Mykolaiv ODA</a><br>
            <a class="indent" target="_blank" href="https://theater.spatialtech.info/en">• Mariupol Drama Theater</a>
    
            
            <p style="font-style: italic; background-color: #f0f0f0; padding: 20px;">
                * Currently, CST team applying this technique to the Chersonesus archaeological site in occupied Crimea. <a href="https://whc.unesco.org/en/list/1411/">This UNESCO World Heritage Site</a> is being manipulated for Russian national myth-building, with rushed construction and ideologically-driven excavations causing irreversible damage. *

                <br><br>

                * By precisely positioning photographs and drone footage in a 3D model, we can document these changes, providing vital evidence of cultural heritage destruction. In this tutorial we will learn to create a base 3D terrain model, match various imagery types to it, and create animations between matched positions. While we use Chersonesus as our case study, these skills can be applied to any site requiring accurate documentation and analysis. * 
            </p>
            
            <h4>Jump to:</h4>

            <a href="#setup">Setup</a>
                <p class="indent">
                    <a href="#software">Software Requirements</a> | <a href="#downloads">Data Downloads</a></p>
            <a href="#base-model">Building the Base Model</a><br>
                <p class="indent">
                    <a href="#DEM">Creating a Base Model with DEM and Satellite Imagery</a><br>
                    <a href="#coordinates">Setup project coordinate system</a> |
                    <a href="#GISmodel">Export GIS data for model</a> | 
                    <a href="#blender-model">Building Mesh model with Blender</a> | 
                    <a href="#base-model">Alternative Methods to Build the Base Model</a>
                </p>
                
                
            <a href="#image-match">Image-Matching</a>
            <p class="indent">
                <a href="#image-camera">Solve Static Image camera position</a> | <a href="#troubleshoot">Troubleshooting a Bad Match</a>
            </p>
            
            <h3 id="setup">Setup</h3>

            <h4 id="software">Software Requirements</h4>
            
            <p>To follow this tutorial, you'll need to have the following software installed:</p>
            <p class="indent">1. <b>Blender</b> (version 3.0 or newer): Blender is a free and open-source 3D creation suite. Download it from blender.org. We will use Blender 4.2.</p>
            <p class="indent">2. <b>Image-matcher Add-on for Blender</b>: This custom add-on enables precise image matching in Blender. You can download it from our <a href="https://github.com/sptch/image-matcher/tree/main">GitHub repository.</a></p>
            <p class="indent">3. <b>Blender-GIS add-on for Blender</b>: This add-on enables the import and manipulation of geospatial data in Blender. Download it from the <a href="https://github.com/domlysz/BlenderGIS">BlenderGIS GitHub repository.</a></p>
            <p class="indent">4. <b>QGIS</b> (latest stable version): QGIS is a free and open-source geographic information system. Download it from <a href="https://qgis.org/en/site/forusers/download.html">qgis.org.</a></p>

            <p>
                Ensure all software is installed and functioning correctly before beginning the tutorial. If you encounter any issues with installation or setup, please refer to the documentation for each software.
            </p>
            
            <h4 id="downloads">Data Downloads</h4>

            <p>For this tutorial, you'll need several types of geospatial data to create a 3D model and match 2D images to it. Download the following datasets:</p>

            <p class="indent">1. <b>ALOS PALSAR Radiometric Terrain Corrected (RTC) Data</b>: This high-resolution digital elevation model (DEM) is derived from radar data. Source: <a href="https://search.asf.alaska.edu/#/?dataset=ALOS">Alaska Satellite Facility (ASF) Data Search.</a></p>
            <p class="indent">2. <b>High-resolution Satellite Imagery</b>: Recent high-resolution imagery of your study area.</p>
            <p class="indent">3. <b>Drone Footage</b>: Aerial imagery captured by drones over your study area.</p>
            <p class="indent">4. <b>Ground-level Photographs</b>: Photographs taken at ground level of key areas in your study site.</p>
            <p class="indent">5. <b>Photogrammetry Model</b> (optional): A detailed 3D model of specific structures within your study area.</p>

            <p>
                To make it easier to follow along with this tutorial, we've prepared a sample dataset that includes all necessary files for the Chersonesus site. You can download this dataset here:
            </p>
            <p>
                Download Sample Dataset (sample_image-match_data.zip)
            </p>

            <h3 id="base-model">Building the Base Model</h3>

            <p>
                In this tutorial, we will demonstrate the use of the <a href="https://github.com/sptch/image-matcher/tree/main">Image-Matcher Add-on for Blender</a> by using the example of aerial photographs around a large-scale archaeological site. This technique can be applied in various contexts and across different model scales, including architectural, interior, and object models.
            </p>
            <p>
                If your primary interest is learning how to use the Image Matcher tool, you can skip the section on building the base model, directly towards <a href="#image-match"></a>Image-matching</a>, as this is only one possible use case for the tool. The add-on is versatile and can be applied to a wide range of scenarios, enabling precise image alignment and location on both small and large-scale models.
            </p>

            <h4>Creating a Base Model with DEM and Satellite Imagery</h4>

            <p>
                A <b>Digital Elevation Model (DEM)</b> provides essential elevation data for 3D terrain modeling. <br>
                Several options for obtaining DEM data, depending on your project’s location and requirements:
            </p>
            <p>
                1. <b>Provided DEM for Chersonesus</b>: You can use the provided .tif file for the Chersonesus site, which contains high-resolution elevation data for the area.
            </p>

        
        <div class="image">
            <img src="./images/imageMatching/image1.webp" alt="DEM">
        </div>

            <p>
                2. <b>ALOS PALSAR DEM</b>: For other regions or more detailed elevation data, you can download high-resolution DEMs from the <b>Alaska Satellite Facility (ASF)</b>. Go to <a href="https://search.asf.alaska.edu/#/?dataset=ALOS">ASF Data Search</a>, select the <b>Hi-Res Terrain Corrected</b> data, and download the .tif file for your area of interest.
            </p>
            
            <div class="image">
            <img src="./images/imageMatching/image2.webp" alt="DEM">
            </div>
            
            <p>
                3. <b>Mapzen Terrain Tiles</b>: As an alternative, you can use the <a href="https://www.mapzen.com/blog/terrain-tile-service/">Mapzen Terrain Tiles</a> dataset, a public source for global elevation data. This tiled dataset offers lower-resolution but easily accessible DEMs, which can be added to QGIS via XYZ-tile connection. Simply configure the URL (<a href="https://s3.amazonaws.com/elevation-tiles-prod/terrarium/{z}/{x}/{y}.png">https://s3.amazonaws.com/elevation-tiles-prod/terrarium/{z}/{x}/{y}.png</a>) in the XYZ-tile connection dialog in QGIS to load global elevation tiles.
            </p>

        <div class="image-fullwidth">

            <div class="image-fullwidth-50">
                <img src="./images/imageMatching/image3.webp" alt="DEM">
                <p class="image-text">
                    Mapzen Terrain Tiles (<a href="https://elevation-tiles-prod.s3.amazonaws.com/index.html#3/0.09/-0.09">  Public Dataset</a>)
                </p>
            </div>

            <div class="image-fullwidth-50">
                <img src="./images/imageMatching/image4.webp" alt="DEM">
                <p class="image-text">QGIS XYZ-tiles connection configuration</p>
            </div>

        </div>

            <p>
                When using <b>satellite imagery</b>, select images captured as close to nadir (directly overhead) as possible. This approach minimizes distortions, especially in areas with varied terrain, reducing the need for complex orthorectification and ensuring a more accurate 3D landscape representation.
            </p>


            <div class="image-fullwidth">
                <div class="image-fullwidth-100">
                    <img src="./images/imageMatching/image5.webp" alt="DEM">
                </div>
            </div>
            <p class="image-text">Evaluating satellite imagery for base model texture</p>
            

            <p>
                When evaluating satellite imagery for your model, consider the terrain’s impact on image quality:
            </p>
            <p class="indent">1. <b>Poor Quality</b>: Significant terrain relief causes noticeable distortions. Steep slopes and tall structures may appear skewed or stretched.</p>
            <p class="indent">2. <b>Acceptable Quality</b>: Less terrain influence, but some distortion still visible on slopes and taller objects.</p>
            <p class="indent">3. <b>Ideal Quality</b>: Minimal terrain-induced distortion. The image appears flattened, with vertical elements and slopes accurately represented.</p>

            <p>
                Select and import your satellite imagery into QGIS
            </p>

            <p>
                With the Digital Elevation Model (DEM) and satellite imagery layers prepared, we are ready to proceed to the next step: building the geometry. This step will involve overlaying the DEM with the satellite imagery to create a textured 3D model, accurately reflecting the terrain’s historical features.
            </p>

            <div class="image-fullwidth">
                <div class="image-fullwidth-50">
                    <img src="./images/imageMatching/image6.webp" alt="DEM">
                    <p class="image-text">Heracles Peninsula DEM tileset. @Mapzen tiles, 2024
                    </p>
                </div>
                <div class="image-fullwidth-50">
                <img src="./images/imageMatching/image7.webp" alt="DEM">
                <p class="image-text">Heracles Peninsula Satelite image. @Google Earth, 2022
                </p>
                </div>
                
            </div>

            <h3>Setup project coordinate system</h3>

            <p>
                For this image-matching tool tutorial, we'll focus on the Ancient City of Tauric Chersonese site and its buffer protected zone.
            </p>
            <div class="image">
                <img src="./images/imageMatching/image8.webp" alt="DEM">
            </div>
            <p class="image-text">The Ancient City of Tauric Chersonese and its buffer zone
            </p>

            <p>
            When zooming in on a particular site, we recommend defining a local coordinate system for 3D modeling and coordination. While optional, we prefer to derive an offset local <b>coordinate reference system (CRS)</b> from the defined regional one. In this case, we'll use <code>UCS-2000 / 3-degree Gauss-Kruger zone 11</code> as the CRS for this area.
            </p>

            <p>
                We'll define a 2000x2000 meter square domain for our model, with a user coordinate system <code>UCS-2000 / Chersonese</code> originating in the square's bottom-left corner.
            </p>

            <div class="image-fullwidth">
                <div class="image-fullwidth-50">
                    <img src="./images/imageMatching/image9.png" alt="DEM">
                    <p class="image-text">Define Custom CRS</p>

                    <img src="./images/imageMatching/image10.png" alt="DEM">
                    <p class="image-text">Select User-Defined or suitable general CRS for your geographic area
                    </p>

                </div>

                <div class="image-fullwidth-50">
                    <pre style="background-color: #f0f0f0;"><code >
                    PROJCRS["UCS-2000 / Chersonese",<br>
                            BASEGEOGCRS["UCS-2000",<br>
                                DATUM["Ukraine 2000",<br>
                                    ELLIPSOID["Krassowsky 1940",6378245,298.3,<br>
                                        LENGTHUNIT["metre",1]]],<br>
                                PRIMEM["Greenwich",0,<br>
                                    ANGLEUNIT["degree",0.0174532925199433]],<br>
                                ID["EPSG",5561]],<br>
                            CONVERSION["3-degree Gauss-Kruger zone 11",<br>
                                METHOD["Transverse Mercator",<br>
                                    ID["EPSG",9807]],<br>
                                PARAMETER["Latitude of natural origin",0,<br>
                                    ANGLEUNIT["degree",0.0174532925199433],<br>
                                    ID["EPSG",8801]],<br>
                                PARAMETER["Longitude of natural origin",33,<br>
                                    ANGLEUNIT["degree",0.0174532925199433],<br>
                                    ID["EPSG",8802]],<br>
                                PARAMETER["Scale factor at natural origin",1,<br>
                                    SCALEUNIT["unity",1],<br>
                                    ID["EPSG",8805]],<br>
                                PARAMETER["False easting",-38220,<br>
                                    LENGTHUNIT["metre",1],<br>
                                    ID["EPSG",8806]],<br>
                                PARAMETER["False northing",-4940800,<br>
                                    LENGTHUNIT["metre",1],<br>
                                    ID["EPSG",8807]]],<br>
                            CS[Cartesian,2],<br>
                                AXIS["northing (X)",north,<br>
                                    ORDER[1],<br>
                                    LENGTHUNIT["metre",1]],<br>
                                AXIS["easting (Y)",east,<br>
                                    ORDER[2],<br>
                                    LENGTHUNIT["metre",1]],<br>
                            USAGE[<br>
                                SCOPE["Heritage site violations documentation, high-precision surveying, and 3D modeling of Tauric Chersonese."],<br>
                                AREA["Ukraine, Crimia. Ancient City of Tauric Chersonese."],<br>
                                BBOX[44.60, 33.48,44.62, 33.51]]]
                    </code></pre>
                    <p class="image-text"><code>UCS-2000 / Chersonese</code> CRS definition</p>
                </div>

            </div>

            <p>
                Using this local coordinate system allows for easy conversion between local Blender model data and world/GIS contexts.
            </p>

            <h3 id="GISmodel">Export GIS data for model</h3>
            <h4>Create an area of interest (AOI) polygon</h4>
            <p>
                Before clipping the DEM and satellite imagery, you need to define the <b>Area of Interest (AOI)</b>. Follow these steps to create an AOI polygon:
            </p>
            <p>
                1. <b>Create a New Shapefile Layer (Vector Layer):</b>
            </p>
            <p class="indent">
                •   In QGIS, go to the top menu and select <code>Layer > Create Layer > New Shapefile Layer…</code><br>
                •   In the dialog box, choose <b>Polygon </b>as the geometry type.<br>
                •   Set the CRS to your custom CRS (or the regional CRS).<br>
                •   Name the file (e.g., 2000.shp) and save it.
            </p>
  
            <p>
                2. <b>Draw the AOI Polygon:</b>
            </p>
            <p class="indent">
                    •   Select the <b>Toggle Editing</b> button for the new shapefile layer in the Layers panel.<br>
                    •   Click the <b>Add Polygon Feature</b> tool from the toolbar.<br>
                    •   Draw a rectangle covering your 2000x2000m area of interest by clicking on the map canvas or using advanced digitizing tools.<br>
                    •   Press <b>Enter or Right Click</b> to finish the polygon and save the shapefile.    
            </p>
            <p>
                3. <b>Save and Exit Editing Mode:</b>
            </p>
            <p class="indent">
                •   After drawing the polygon, click Toggle Editing again, and choose Save when prompted.
            </p>

            <h4>Clip and export selected layers</h4>
            <p>There are two option we can save clipped region:</p>
            <p class="indent">
                1. Clipping raster <code>Raster > Extraction > Clip Raster by Mask Layer. </code> <br>
                2. Export layer with clipping boundaries <code>Right-Click on the Raster Layer in the Layers Panel > Select “Export” > “Save As…”</code>
            </p>

            <p>
                While the “<b>Clip Raster by Mask Layer</b>” method generally offers better precision and higher quality, we recommend using it for most clipping tasks. However, when working with raster tiles, this method may not be supported. In such cases, we suggest using the <b>“Export” > “Save As”</b> option, which is more suitable for clipping tiled datasets or formats that don’t allow the use of the “Clip Raster by Mask Layer” tool.
            </p>

            <div class="image-fullwidth">
                <div class="image-fullwidth-50">
                    <img src="./images/imageMatching/image11.png" alt="DEM">
                    <p class="image-text">Clip Raster by Mask Layer. Properties for TIFF-souce layer </p>
                </div>

                <div class="image-fullwidth-50">
                    <img src="./images/imageMatching/image12.png" alt="DEM">
                    <p class="image-text">“Export” > “Save As”. Properties for XYZ-raster-tiles-source layer.</p>
                </div>
            </div>
            <div class="image-fullwidth">
                <div class="image-fullwidth-100">
                    <img src="./images/imageMatching/image13.png" alt="DEM">
                    <p class="image-text">Exported Satellite and DEM raster.</p>
                </div>
            </div>

        <h3 id="blender-model">Building Mesh model with Blender</h3>

        <p>

        </p>









    
        </div>
        
    </div>
</div>

    <script>
        let tutorialsData;
        let colorsData;

        function loadData() {
            // Load both JSON files
            d3.json("../tutorials.json").then(function(loadedData) {
                tutorialsData = loadedData;
                d3.json("../colors.json").then(function(loadedColors) {
                    colorsData = loadedColors;
                    displayTagsAndPanel();
                });
            });
        }

        function getColorForTag(tag) {
            // Find the panel color for a given tag
            const colorEntry = colorsData.colors.find(colorEntry => colorEntry.tags.includes(tag));
            return colorEntry ? colorEntry.color : "#CCCCCC"; // Default to grey if not found
        }

        function getPanelColor(panel) {
            // Find the color for a given panel
            const colorEntry = colorsData.colors.find(colorEntry => colorEntry.panel === panel);
            return colorEntry ? colorEntry.color : "#CCCCCC"; // Default to grey if not found
        }

        function displayTagsAndPanel() {
            const projectName = document.body.getAttribute("data-project-name");
            const tagContainer = document.getElementById("project_tags");
            const panelTextElement = document.getElementById("panel-text");
            const circleElement = document.querySelector(".tutorials-circle");

            const project = tutorialsData.tutorials.find(tutorial => tutorial.project === projectName);

            if (project) {
                panelTextElement.innerText = project.panel;

                // Find and set the color for the panel
                const panelColor = getPanelColor(project.panel);
                circleElement.style.backgroundColor = panelColor;

                // Display and color the tags
                project.tags.forEach(tag => {
                    const tagElement = document.createElement("div");
                    tagElement.className = "tag-item";
                    tagElement.innerText = tag;
                    tagElement.style.backgroundColor = getColorForTag(tag); // Use color for each tag
                    tagContainer.appendChild(tagElement);
                });
            }
        }

        document.getElementById('sidePanel').addEventListener('click', function() {
            window.location.href = '../index.html'; 
        });

        loadData(); // Call the loadData function to load the JSON and display the tags and panel text
    </script>
</body>

</html>