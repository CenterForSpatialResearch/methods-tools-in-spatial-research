<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reconstructing Historical Events: The Babyn Yar Models Project</title>
    <link rel="stylesheet" href="../main.css">
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@300&display=swap" rel="stylesheet">
    <script src="https://www.gstatic.com/charts/loader.js"></script>
    <script src="https://code.jquery.com/jquery-1.12.4.js"></script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-J2SEN9LXNV"></script>
    <script src="https://d3js.org/d3.v6.min.js"></script>
</head>

<body data-project-name="Reconstructing Historical Events"> <!-- MATCH project name from tutorials.json -->
    <div class="top-bar">
   
        <div class="title">
            <a href="../index.html" id="sidePanel">
                Methods and Tutorials in Spatial Research 
            </a>
        </div>

        <div class="button-container" id="about">
            <a href="../about.html">About</a>
        </div>
     </div>


     <div class="column">
        <div class="column-left">
            <div id="tutorials-side-panel">
                <h6>
                    Currently viewing tutorial page, <br><a href="../index.html">click here to return to main page.</a>
                </h6>

                <h3>Workshop Panel: </h3>
                <div class="visual-code-container">
                    <div class="tutorials-circle"></div>
                    <p id="panel-text"></p>
                </div>
                <h3>Project Tags: </h3>
                <div class="tutorials-ProjectTagsContainer" id="project_tags">
                    <!-- Tags will be dynamically inserted here -->
                </div>
            </div>

        </div>
        <div class="main">

            <div class="tutorials-section">
                
                <h1>Reconstructing Historical Events: The Babyn Yar Models Project</h1> <!-- MATCH with title above in head -->
                <h2>Maksym Rokmaniko, The Center for Spatial Technologies</h2>

                <p>Jump to:</p>
                <a href="#reconstruct-guide">Guide Overview</a><br>
                <a href="#reconstruct-DEM">Building a Digital Elevation Model (DEM)</a><br>
                <a class="indent" href="#reconstruct-source">Processing of Source Materials</a><br>
                <a class="indent" href="#reconstruct-contour">Vectorization of Contour Lines</a><br>
                <a href="#reconstruct-georef-aerial">Georeferencing Aerial Photographs</a><br>
                <a href="#reconstruct-georef-histo">Georeferencing Historical Photographs</a>
                
                <h3>About the project</h3>

                <p>Babyn Yar Models is a project that spatially reconstructs the historical events of Babyn Yar around the transformations of its landscape. Working with maps, aerial photographs, photos, videos, eyewitness stories, and historical research, our team reconstructed the lost landscape of Babyn Yar and, through its transformations, followed the course of historical events.</p>

                <p>On September 29-30, 1941, more than 33,000 Jews were massacred in Babyn Yar. During the German occupation of Kyiv, between 100,000 and 150,000 people were killed there, including patients of the Kyiv City Psychiatric Hospital, Roma, Ukrainian nationalists, prisoners of war, and local authorities. Before retreating from Kyiv, the Nazis attempted to hide the traces of the massacres. Several hundred prisoners of war from the Syrets internment camp were forced to exhume and burn the remains of the dead.</p>

                <p>In the late 50s and early 60s, the landscape of Babyn Yar was fundamentally changed. The spurs were filled with liquid soil and covered over, resulting in the disappearance of the ravine as such. Highways were laid on the territory of Babyn Yar, and a residential area and a park were built. The area has changed so much that even historians argued about the exact location of the mass executions.</p>

                <p>In order to help better understand the important historical events of Babyn Yar, this  project reconstructs the landscape where those events happened.</p>


        
            <iframe class="iframe" src="https://www.youtube-nocookie.com/embed/J8LsLWtRLcw?si=DE3eG6p9DjkyJKhP" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        

                <p class="image-text">Babyn Yar Models presentation video ©Center for Spatial Technologies 2021</p>

                <h3 id="reconstruct-guide">Guide overview</h3>

                <p>This guide outlines the general methodology for reconstructing a historical landscape using a variety of media sources. These sources include archival drawings, maps, aerial and satellite photographs, as well as ground-level photographs and videos. The guide describes the processes and techniques used to work with diverse data types – such as topographic maps and photogrammetry – to build a spatial model of a transformed landscape.</p>

            <h3 id="reconstruct-DEM">Building a Digital Elevation Model (DEM)</h3>

                <p>We sourced topographic surveys and aerial photographs from different periods to build a Digital Elevation Model (DEM) of Babyn Yar. Using specialized software like AutoCAD, QGIS, Blender, and Grasshopper for Rhinoceros 3D, we navigated the challenges of integrating varying coordinate systems and correcting map distortions to accurately reconstruct the historical landscape.</p>

                <h4 id="reconstruct-source">Processing of Source Materials</h4>

                <p>Most source materials required significant pre-processing. Archival maps, for example, often had visible seams, and aerial reconnaissance photographs contained distortions. To ensure usability, we corrected these issues through alignment, calibration, and distortion adjustments. This involved preparing template files for each map sheet and using QGIS Georeferencer to align the maps to a 100x100 fathom orthogonal grid.</p>

                <div class="image"><img src="./images/ReconstructingHistoricalEvents/RasterDeformation-and-OrthogonalGridAlignment.gif" alt="Raster Deformation and Ortho Grid"></img></div>

                <p class="image-text">Raster Deformation and Orthogonal Grid Alignment ©Center for Spatial Technologies 2020</p>
            
                <h4 id="reconstruct-contour">Vectorization of Contour Lines</h4>

                <p>For topographic maps, color filters were applied to isolate contour lines, and superfluous elements were removed to enhance clarity. These images were then imported into a CAD environment, where each contour line was vectorized and elevated to its respective height using Bitonal mode. This crucial step allowed for the precise creation of a three-dimensional terrain model.</p>

                <div class="image"><img src="./images/ReconstructingHistoricalEvents/kyivTopoMap.png" alt="1923 Kyiv Topo Map"></img></div>
                <p class="image-text">A processed fragment of a topographic map of Kyiv from 1923. ©Center for Spatial Technologies, 2020</p>

                <div class="image"><img src="./images/ReconstructingHistoricalEvents/CADKyivContourLines.png" alt="Topo Lines from Archive Drawing"></img>
                <p class="image-text">The process of drawing topographic lines from archival drawings. ©Center for Spatial Technologies, 2020</p>

                <div class="image"><img src="./images/ReconstructingHistoricalEvents/RasterToVector.png" alt="Grid Transition from Raster to Vector Lines"></img>
                <p class="image-text">Transition from original raster to vectorized contour lines: raw map (left), level inversion (center), and vectorized contour lines (right). ©Center for Spatial Technologies, 2020</p>

                <div class="image"><img src="./images/ReconstructingHistoricalEvents/Babyn_Yar_Models___CST_for_BYHMC_work_in_progress.gif" alt="CST Babyn Yar Model 3d Model from Topo Lines"></img>
                <p class="image-text">Forming a three-dimentional model of the terrain based on the topographic lines. ©Center for Spatial Technologies, 2020</p>

                <div class="image"><img src="./images/ReconstructingHistoricalEvents/model1924.png" alt="3d model of 1924 Babyn Yar landscape"></img>
                <p class="image-text">A model of the Babyn Yar landscape as of 1924. ©Center for Spatial Technologies, 2020</p>

                <div class="image"><img src="./images/ReconstructingHistoricalEvents/model2020.png" alt="3d model of 2020 Babyn Yar landscape"></img>
                <p class="image-text">A model of the Babyn Yar landscape as of 2020. ©Center for Spatial Technologies, 2020</p>


            <h3 id="reconstruct-georef-aerial">Georeferencing Aerial Photographs</h3>

                <p>
                    The georeferencing process involves overlaying archival aerial photographs and maps onto the 3D terrain model to better understand the historical landscape. The process begins by collecting archival materials from different archives. The topographic maps are aligned using buildings from the 1920s that still stand today as reference points. Photogrammetry tools are then used to georeference the aerial photographs, accurately determine camera positions, and reproject the original images onto a 3D terrain model of the area. This georeferencing is essential for ensuring that the historical images align correctly with the modern landscape, providing a reliable foundation for further analysis and reconstruction.
                </p>

                <div class="image"><img src="./images/ReconstructingHistoricalEvents/footageColleciton.png" alt="Reconnaissance Footage"></img>
                    <p class="image-text">Collection of German reconnaissance footage from 1939, 1941, 1943, and 1944. ©Center for Spatial Technologies, 2020</p>
                
                <div class="image"><img src="./images/ReconstructingHistoricalEvents/stereoscopicImagePair.png" alt="Stereoscopic image pairs"></img>
                <p class="image-text">Stereoscopic image pairs used for terrain photogrammetry and lens distortion correction. ©Center for Spatial Technologies, 2020</p>

                <div class="image"><img src="./images/ReconstructingHistoricalEvents/topoAerialMaps.png" alt="Aligned Topo Maps"></img>
                <p class="image-text">Topographic maps and aerial images are aligned using buildings from the 1920s that still stand today as reference points. ©Center for Spatial Technologies, 2020</p>

                <div class="image"><img src="./images/ReconstructingHistoricalEvents/AerialTerrain.png" alt="Babyn Yar terrain from 1943"></img>
                <p class="image-text">Bird’s-eye view of the Babyn Yar terrain from 1943, overlaid with an aerial image. ©Center for Spatial Technologies, 2020.</p>


            <h3 id="reconstruct-georef-histo">Georeferencing Historical Photographs</h3>

                <p>
                    The process of geolocating of the historic photographs relies on the. By creating a detailed 3D model of the landscape as it existed in the past, historical images can be accurately placed within their geographical context. This method allows a deeper understanding of the historical site and the events that took place there, enhancing both the interpretation of photographs and the landscape itself, providing crucial insights for research and reconstruction.
                </p>

                <p>
                    We worked with a diverse range of photographic materials, gathering images from various archives, tracking down originals, and carefully excluding pictures that were not actually from Babyn Yar (which were surprisingly numerous in Google search results for "Babyn Yar").   
                </p>

                <div class="image"><img src="./images/ReconstructingHistoricalEvents/photoFilm.png" alt="Photo Film"></img>
                <p class="image-text">Photo film by Johannes Hähle. Photographs numbered 6-18 are taken in Babyn Yar. ©Hamburg Institute for Social Research.</p>

                <p>
                    The next step is to identify the terrain features visible in both photographs and aerial images/models. For example, on the bird's-eye view model of the site below, a large grassy hill with a tree line in the background is visible. This distinctive hill can be identified in photographs from the 1940s, providing a consistent reference point across different time periods. Through the angle from which this hill is visible, we identified the locations of several key photographs.
                </p>

                <div class="image"><img src="./images/ReconstructingHistoricalEvents/keyFeatures.png" alt="Identification of the key terrain features"></img>
                <p class="image-text">Identification of the key terrain features (photographs numbered 16 and 17 from the Johannes Hähle film), visible on the aerial images. ©Center for Spatial Technologies, 2021.</p>

                <div class="image"><img src="./images/ReconstructingHistoricalEvents/VhillModel.png" alt="Hill with V-shaped grass on the bird’s-eye view model of Babyn Yar"></img>
                <p class="image-text">The hill with V-shaped grass on the bird’s-eye view model of Babyn Yar. ©Center for Spatial Technologies, 2021.</p>

                <div class="image"><img src="./images/ReconstructingHistoricalEvents/modelToPhotos.gif" alt="Different photographs from the 1940s showing a hill with V-shaped"></img>
                <p class="image-text">Different photographs from the 1940s showing a hill with V-shaped grass, visible from multiple angles. ©Center for Spatial Technologies, 2021.</p>

                <p>
                    This work led us to develop the <a href="https://github.com/sptch/image-matcher/tree/main">Image-matcher Add-on for Blender plugin</a>, which we also used in our later analysis of the <a href="https://www.spatialtech.info/en/works/tv-tower">Russian attack on Kyiv TV tower</a>, the <a href="https://www.spatialtech.info/en/works/mykolaiv">missile strike on Mykolaiv ODA</a>, and our in-depth study of the <a href="https://theater.spatialtech.info/en">Russian bombing of the Mariupol Drama Theater</a>. For more details on how to use this add-on we created a separate tutorial, available <a href="./ImageMatching.html">here</a>. 
                </p>

                <p>
                    Presented below are the located photographs:
                </p>

                <div class="image"><img src="./images/ReconstructingHistoricalEvents/siteHistoricalPhotos.gif" alt="Contemporary Babyn Yar overlaid with the terrain of the historic ravines"></img>
                <p class="image-text">Contemporary territory of Babyn Yar overlaid with the terrain of the historic ravines, including exact locations of historic photographs. ©Center for Spatial Technologies, 2021.</p>

            </div>
        </div>
    </div>

    <script>
        let tutorialsData;
        let colorsData;

        function loadData() {
            // Load both JSON files
            d3.json("../tutorials.json").then(function(loadedData) {
                tutorialsData = loadedData;
                d3.json("../colors.json").then(function(loadedColors) {
                    colorsData = loadedColors;
                    displayTagsAndPanel();
                });
            });
        }

        function getColorForTag(tag) {
            // Find the panel color for a given tag
            const colorEntry = colorsData.colors.find(colorEntry => colorEntry.tags.includes(tag));
            return colorEntry ? colorEntry.color : "#CCCCCC"; // Default to grey if not found
        }

        function getPanelColor(panel) {
            // Find the color for a given panel
            const colorEntry = colorsData.colors.find(colorEntry => colorEntry.panel === panel);
            return colorEntry ? colorEntry.color : "#CCCCCC"; // Default to grey if not found
        }

        function displayTagsAndPanel() {
            const projectName = document.body.getAttribute("data-project-name");
            const tagContainer = document.getElementById("project_tags");
            const panelTextElement = document.getElementById("panel-text");
            const circleElement = document.querySelector(".tutorials-circle");

            const project = tutorialsData.tutorials.find(tutorial => tutorial.project === projectName);

            if (project) {
                panelTextElement.innerText = project.panel;

                // Find and set the color for the panel
                const panelColor = getPanelColor(project.panel);
                circleElement.style.backgroundColor = panelColor;

                // Display and color the tags
                project.tags.forEach(tag => {
                    const tagElement = document.createElement("div");
                    tagElement.className = "tag-item";
                    tagElement.innerText = tag;
                    tagElement.style.backgroundColor = getColorForTag(tag); // Use color for each tag
                    tagContainer.appendChild(tagElement);
                });
            }
        }

        document.getElementById('sidePanel').addEventListener('click', function() {
            window.location.href = '../index.html'; 
        });

        loadData(); // Call the loadData function to load the JSON and display the tags and panel text
    </script>
</body>

</html>