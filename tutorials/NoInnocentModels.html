<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>No Innocent Models: Creating OBAI</title>
    <link rel="stylesheet" href="../main.css">
    <script src="https://code.jquery.com/jquery-1.12.4.js"></script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-J2SEN9LXNV"></script>
    <script src="https://d3js.org/d3.v6.min.js"></script>

</head>
<body data-project-name="No Innocent Models"> <!-- The name here is to link Tags from json file (project name)-->
    <div class="top-bar">
        <div class="menu">
            <a href="../about/about.html">ABOUT</a>
        </div>
    </div>

    <div class="title"  id="sidePanel">
        <p>
            Methods and Tutorials in Spatial Research 
        </p>
    </div>

    <div class="tutorials-side-panel">
        <h3 style="font-family: UniversNextW01-Regular,Helvetica,Arial,sans-serif;">Workshop Panel: </h3>
        <div class="visual-code-container">
            <div class="tutorials-circle"></div>
            <p id="panel-text" style="font-family: 'UniversNextW01-Regular', Helvetica, Arial, sans-serif; font-weight: bold;"></p>
        </div>
        <h3>Project Tags: </h3>
        <div class="tutorials-ProjectTagsContainer" id="project_tags">
            <!-- Tags will be dynamically inserted here -->
        </div>
    </div>
    

    </div>

    <div class="tutorials-section">
        <h1>No Innocent Models</h1>
        <h3>Beth Coleman with Evangeline Brooks</h3>

        <div style="height: 20px;"></div> <!-- Adds space -->
        <img src="./images_NoInnocentModelsCreatingOBAI/image1.png" alt="Hero Image" class="tutorials-image">
        <p style="margin-top: -40px; text-align: center; font-size: 18px;">Figure 1: OBAI diagram: environment, agent, state, reward, action B. Coleman 2023. Photo Credit: Beth Coleman.</p>
        
        <h3>BREAK THE MACHINE</h3>
        <p>Reality Was Whatever Happened. Octavia Butler AI and Other Possible Worlds (OBAI) marks the “generative” element that speculative fiction, like Butler’s own, produces. In the space of machine learning, OBAI attempts to slip past the border patrol that maintains the distinction of the human/non-human. Coleman enlisted a Generative Adversarial Network (GAN), for the image production. Importantly, generative modeling functions as an unsupervised learning task: sorting through unlabeled data to build patterns and map commonalities. The constraint―although clearly this is not limited to AI―might be put this way: How has meaning been locked into a system?
        </p>

        <h3>WHAT IS A MODEL</h3>
        <p>Effectively Reality Was Whatever Happened works along the following axes:</p>
        <p>a) the technological stack or architecture demonstrates the ontology that there are no innocent models. If a systems is trained to distinguish white dogs or desert landscapes or colonial drawings of birds particular world view, angles, and framings are captured and set as a standard. In other words, one can comprehend predictive models as generative of standards.</p>
        <p>b) articulating through design a comprehension of model ontology sufficient to break it: how might generative AI supersede a reinscription of the normative. </p>

        <h3>PROCEDURE</h3>
        <p>The advantage of the GAN system design, pivotal at a certain point of generative AI development, is its speed and light data load with powerful outcomes. Before introducing new data or a novel dataset, the GAN is pretrained on sets of images—faces, landscapes, animals, etc. There is a generation of type based on the distinct training corpus: what are the properties of the human face; what are the types of trees, and so on. Within the GAN there are two dynamic components, a generator and a detector (m1 & m2) that iterate back and forth until the system recognizes parity between image generation based on new data and the benchmark of the training data: faces look like faces; white dogs are not white wolves.</p>
        <p>With Reality Was Whatever Happened, the question went somewhere along the lines of, What if the thing generated to be detected is alien. Not a match of same but the generation of difference. In this sense OBAI leveraged GAN  affordances of high outcome with law data input to formulate hand-curated data sets that work against the grain of normative reinscription. In other words, to actually generate.
        </p>
        <p>Generation one, the Alice series was comprised of a set of black feminine figures. That initial system tuning toward a contrapuntal GAN production.
        </p>
        <img src="./images_NoInnocentModelsCreatingOBAI/image2.png" alt="Placeholder" class="tutorials-image">
        <p style="margin-top: -40px; text-align: center; font-size: 18px;">Figure 2: Generation two, Oceanic enlisted ocean figures to train on the Alice GAN. Photo Credit: Beth Coleman.</p>
        <img src="./images_NoInnocentModelsCreatingOBAI/image3.png" alt="Placeholder" class="tutorials-image">
        <p style="margin-top: -40px; text-align: center; font-size: 18px;">Figure 3: Generation three, BPP Landscapes, are related in process but use a new GAN model to interpolate arrays of paramilitaristic grouping into landscapes (not pictured). Photo Credit: Beth Coleman.
        </p>
        <p>Generation three, BPP Landscapes, are related in process but use a new GAN model to interpolate arrays of paramilitaristic grouping into landscapes (not pictured).
        </p>
        <p>Instead of detecting face for face in a normalizing account, OBAL GAN searched face and creatures, ocean, land…The drive to match as it was built into the system is overdriven to produce parity in the face of the incommensurate. Making kin with aliens.
        </p>
        <p>All images B. Coleman 2023	<a href="realitywaswhateverhappened.com">realitywaswhateverhappened.com</a></p>
        
        <hr style="width: 100%; margin: 40px auto;">
        
        <p>Here is an example of a tutorial we have shared with other speakers to reference:</p>
        <p>
          <a href="https://centerforspatialresearch.github.io/methods-in-spatial-research-sp2024/tutorials/webmap-2/" target="_blank">
            Web Map Tutorial
          </a>
        </p>
        
        <p>Jia Zhang’s Asian American Dot Density Map, which shares steps, but also links to outside articles/tutorials for more basic procedures:</p>
        <p>
          <a href="https://medium.com/uncharted-singles/asian-american-dot-density-map-84271a4e68cd" target="_blank">
            Asian American Dot Density Map
          </a>
        </p>
        
        <p>Soph & Sasha’s Open Weather DIY Ground Station. Much longer than needed:</p>
        <p>
          <a href="https://open-weather.community/diy-satellite-ground-station/" target="_blank">
            Open Weather DIY Ground Station
          </a>
          <br>
          <a href="https://apt.open-weather.community/" target="_blank">
            APT Open Weather Community
          </a>
        </p>
        
        <p>Forensic Architecture and Nicholas Masterton’s Camera Dolly Set up:</p>
        
    </div>

    <div id="project_tags" class="tag-grid"></div>

    <script>
        let tutorialsData;
        let colorsData;

        function loadData() {
            // Load both JSON files
            d3.json("../tutorials.json").then(function(loadedData) {
                tutorialsData = loadedData;
                d3.json("../colors.json").then(function(loadedColors) {
                    colorsData = loadedColors;
                    displayTagsAndPanel();
                });
            });
        }

        function getColorForTag(tag) {
            // Find the panel color for a given tag
            const colorEntry = colorsData.colors.find(colorEntry => colorEntry.tags.includes(tag));
            return colorEntry ? colorEntry.color : "#CCCCCC"; // Default to grey if not found
        }

        function getPanelColor(panel) {
            // Find the color for a given panel
            const colorEntry = colorsData.colors.find(colorEntry => colorEntry.panel === panel);
            return colorEntry ? colorEntry.color : "#CCCCCC"; // Default to grey if not found
        }

        function displayTagsAndPanel() {
            const projectName = document.body.getAttribute("data-project-name");
            const tagContainer = document.getElementById("project_tags");
            const panelTextElement = document.getElementById("panel-text");
            const circleElement = document.querySelector(".tutorials-circle");

            const project = tutorialsData.tutorials.find(tutorial => tutorial.project === projectName);

            if (project) {
                panelTextElement.innerText = project.panel;

                // Find and set the color for the panel
                const panelColor = getPanelColor(project.panel);
                circleElement.style.backgroundColor = panelColor;

                // Display and color the tags
                project.tags.forEach(tag => {
                    const tagElement = document.createElement("div");
                    tagElement.className = "tag-item";
                    tagElement.innerText = tag;
                    tagElement.style.backgroundColor = getColorForTag(tag); // Use color for each tag
                    tagContainer.appendChild(tagElement);
                });
            }
        }

        document.getElementById('sidePanel').addEventListener('click', function() {
            window.location.href = '../index.html'; 
        });

        $(document).ready(function(){
            $('#scrollToLink').click(function(e){
                e.preventDefault();
                $('html, body').animate({
                    scrollTop: $('#targetLink').offset().top
                }, 800);
            });
        });

        loadData(); // Call the loadData function to load the JSON and display the tags and panel text
    </script>

</body>
</html>
